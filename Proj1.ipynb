{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v83DNlt-bRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVzK1YvL-gBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseModel:  \n",
        "  lines=[]\n",
        "  input_words = []\n",
        "  output_words = []\n",
        "  chars = set()\n",
        "  nb_samples = 0\n",
        "\n",
        "  index_to_char_dict = {}\n",
        "  char_to_index_dict = {}\n",
        "  max_len_input_words = 0\n",
        "  max_len_output_words = 0\n",
        "  tokenized_input_words=[]\n",
        "  tokenized_output_words=[]\n",
        "  target_data=[]\n",
        "  def __init__(self,inputWords,outputWords):\n",
        "    self.nb_samples=len(inputWords)\n",
        "    self.input_words=inputWords\n",
        "    self.output_words=outputWords\n",
        "    self.__modifyOutputChars();\n",
        "    self.__getCharsFromWords();\n",
        "    self.__setDictionaries();\n",
        "    self.max_len_input_words = max([len(line) for line in self.input_words])\n",
        "    self.max_len_output_words = max([len(line) for line in self.output_words])\n",
        "    self.tokenized_input_words = np.zeros(shape = (self.nb_samples,self.max_len_input_words,len(self.chars)), dtype='float32')\n",
        "    self.tokenized_output_words = np.zeros(shape = (self.nb_samples,self.max_len_output_words,len(self.chars)), dtype='float32')\n",
        "    self.target_data = np.zeros((self.nb_samples, self.max_len_output_words, len(self.chars)),dtype='float32')\n",
        "    self.__tokenizeData();\n",
        "\n",
        "  def __modifyOutputChars(self):\n",
        "    self.output_words=['\\t'+line+'\\n' for line in self.output_words]   \n",
        "\n",
        "\n",
        "  def __getCharsFromWords(self):\n",
        "\n",
        "    for line in range(self.nb_samples):\n",
        "      input_word = self.input_words[line]    \n",
        "      output_word = self.output_words[line]\n",
        "\n",
        "      for ch in input_word:\n",
        "        if (ch not in self.chars):\n",
        "          self.chars.add(ch)\n",
        "\n",
        "      for ch in output_word:\n",
        "        if (ch not in self.chars):\n",
        "          self.chars.add(ch)\n",
        "\n",
        "  def __setDictionaries(self):\n",
        "    self.chars = sorted(list(self.chars))\n",
        "    for k, v in enumerate(self.chars):\n",
        "      self.index_to_char_dict[k] = v\n",
        "      self.char_to_index_dict[v] = k\n",
        "\n",
        "  def __tokenizeData(self):\n",
        "    for i in range(self.nb_samples):\n",
        "      for k,ch in enumerate(self.input_words[i]):\n",
        "        self.tokenized_input_words[i,k,self.char_to_index_dict[ch]] = 1\n",
        "        \n",
        "        for k,ch in enumerate(self.output_words[i]):\n",
        "          self.tokenized_output_words[i,k,self.char_to_index_dict[ch]] = 1\n",
        "        \n",
        "          if k > 0:\n",
        "            self.target_data[i,k-1,self.char_to_index_dict[ch]] = 1\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OAvz7rg-hUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Char2CharNet:\n",
        "  dataModel={}\n",
        "  model={}\n",
        "  encoder_model_inf={}\n",
        "  history={}\n",
        "  chars=0\n",
        "  def __init__(self,dataModel):   \n",
        "    self.chars=dataModel.chars \n",
        "    self.dataModel=dataModel\n",
        "    encoder_input = Input(shape=(None,len(dataModel.chars)))\n",
        "    encoder_LSTM = LSTM(512,return_state = True)\n",
        "    encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
        "    encoder_states = [encoder_h, encoder_c]\n",
        "\n",
        "    decoder_input = Input(shape=(None,len(dataModel.chars)))\n",
        "    decoder_LSTM = LSTM(512,return_sequences=True, return_state = True)\n",
        "    decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(len(dataModel.chars),activation='softmax')\n",
        "    decoder_out = decoder_dense (decoder_out)\n",
        "    self.model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
        "    \n",
        "    \n",
        "    self.encoder_model_inf = Model(encoder_input, encoder_states)\n",
        "\n",
        "    decoder_state_input_h = Input(shape=(512,))\n",
        "    decoder_state_input_c = Input(shape=(512,))\n",
        "    decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, initial_state=decoder_input_states)\n",
        "    decoder_states = [decoder_h , decoder_c]\n",
        "    decoder_out = decoder_dense(decoder_out)\n",
        "    self.decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states, outputs=[decoder_out] + decoder_states )\n",
        " \n",
        "  def trainModel(self):\n",
        "      \n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    self.history=self.model.fit(x=[self.dataModel.tokenized_input_words,self.dataModel.tokenized_output_words], \n",
        "          y=self.dataModel.target_data,\n",
        "          batch_size=64,\n",
        "          epochs=30,\n",
        "          validation_split=0.15)\n",
        "    \n",
        "  def plotLoss(self):\n",
        "    plt.plot(self.history.history['loss'])\n",
        "    plt.plot(self.history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "  def plotAccuracy(self):\n",
        "    plt.plot(self.history.history['accuracy'])\n",
        "    plt.plot(self.history.history['val_accuracy'])\n",
        "    plt.title('model acc')\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "  def decode_seq(self,inp_seq):\n",
        "    test = np.zeros(shape = (1,self.dataModel.max_len_input_words,len(self.chars)), dtype='float32')\n",
        "    for k,ch in enumerate(inp_seq):\n",
        "        test[0,k,self.dataModel.char_to_index_dict[ch]] = 1\n",
        "  \n",
        "    states_val = self.encoder_model_inf.predict(test)  \n",
        "    target_seq = np.zeros((1, 1, len(self.chars)))\n",
        "    target_seq[0, 0, self.dataModel.char_to_index_dict['\\t']] = 1\n",
        "    translated_sent = ''\n",
        "    stop_condition = False\n",
        "\n",
        "    while not stop_condition:        \n",
        "        decoder_out, decoder_h, decoder_c = self.decoder_model_inf.predict(x=[target_seq] + states_val)        \n",
        "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
        "        sampled_pol_char = self.dataModel.index_to_char_dict[max_val_index]\n",
        "        translated_sent += sampled_pol_char\n",
        "        \n",
        "        if ( (sampled_pol_char == '\\n') or (len(translated_sent) > self.dataModel.max_len_output_words)) :\n",
        "            stop_condition = True\n",
        "        \n",
        "        target_seq = np.zeros((1, 1, len(self.chars)))\n",
        "        target_seq[0, 0, max_val_index] = 1\n",
        "        \n",
        "        states_val = [decoder_h, decoder_c]  \n",
        "    translated_sent = translated_sent[:-1]   \n",
        "    return translated_sent"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFxw7WKs-ixU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProjectML():\n",
        "  maleModel= BaseModel\n",
        "  maleNet=Char2CharNet\n",
        "\n",
        "  femaleModel= BaseModel  \n",
        "  femaleNet=Char2CharNet\n",
        "\n",
        "  def __init__(self):    \n",
        "    lines = open('derywaty.txt', encoding='utf-8').read().split('\\n')\n",
        "    female_words = []\n",
        "    male_words = [] \n",
        "    for line in range(len(lines)-1):\n",
        "      female_word = str(lines[line]).split('\\t')[0]    \n",
        "      male_word = str(lines[line]).split('\\t')[1]\n",
        "      female_words.append(female_word)\n",
        "      male_words.append(male_word)\n",
        "\n",
        "    self.maleModel= BaseModel(female_words,male_words)\n",
        "    self.maleNet=Char2CharNet(self.maleModel);\n",
        "\n",
        "    self.femaleModel= BaseModel(male_words,female_words)\n",
        "    self.femaleNet=Char2CharNet(self.femaleModel);\n",
        "\n",
        "  def TrainMaleModel(self):\n",
        "    self.maleNet.trainModel()    \n",
        "\n",
        "  def TrainFemaleModels(self):\n",
        "    self.femaleNet.trainModel()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXEQIvO6-kOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mod=ProjectML()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqiicecoBf9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ced77d52-2bbf-4d89-a1fa-b245382d5f85"
      },
      "source": [
        "mod.TrainMaleModel()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2793 samples, validate on 493 samples\n",
            "Epoch 1/30\n",
            "2793/2793 [==============================] - 12s 4ms/step - loss: 1.1058 - accuracy: 0.0510 - val_loss: 1.0583 - val_accuracy: 0.0609\n",
            "Epoch 2/30\n",
            "1600/2793 [================>.............] - ETA: 3s - loss: 1.0160 - accuracy: 0.0624"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYusbluWFwGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mod.TrainFemaleModels()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dxLAvSY-lxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(mod.maleNet.decode_seq(\"tkaczka\"))\n",
        "print(mod.femaleNet.decode_seq(\"lekarz\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5_LPMlXF-ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print('male Net')\n",
        "mod.maleNet.plotLoss()\n",
        "mod.maleNet.plotAccuracy()\n",
        "\n",
        "print('female Net')\n",
        "mod.femaleNet.plotLoss()\n",
        "mod.femaleNet.plotAccuracy()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}